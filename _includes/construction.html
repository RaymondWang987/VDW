<section class="bg-primary" style="background-color:#E6E7E8;opacity: 0.5;height: 200%;padding:2% 5% 2% 5%;" id="construction">
    <!-- <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">We've got what you need!</h2>
                <hr class="light">
                <p class="text-faded">Start Bootstrap has everything you need to get your new website up and running in no time! All of the templates and themes on Start Bootstrap are open source, free to download, and easy to use. No strings attached!</p>
                <a href="#" class="btn btn-default btn-xl">Get Started!</a>
            </div>
        </div>
    </div> -->
    <div style="height: 16%;" class="col-md-6 col-sm-6 text-center">
        <!-- <img style="max-width: 80%;max-height: 90%;" src="construct_page-0001.jpg" > -->
        <img style="max-width: 100%;max-height: 100%;border-radius:2%" src="construct_page-0001.jpg" >
    </div>
    <div style="height: 16%;" class="col-md-6 col-sm-6 text-center">
        <div style="vertical-align: middle;">
            <h1 style="color: black;margin-top:8%;">
                <span style="font-weight: 1000;font-family: Caveat">Overall Description</span> 
            </h1>
            <h4 style="color: black;text-align: left;margin-top:4%;font-family:Calibri;">
                Current video depth datasets are limited in both diversity and volume. 
                To compensate for the data shortage and boost the performance of learning-based video depth models, 
                we elaborate a large-scale natural-scene dataset, 
                <span style="font-weight: 800;">Video Depth in the Wild (VDW)</span>. 
                To the best of our knowledge, our VDW dataset is currently 
                <span style="font-weight: 800;">the largest</span> video depth dataset with <span style="font-weight: 600;">the most diverse</span> video scenes.
            </h4>
        </div>
    </div>

    <div style="height: 16%;margin-top: 2%;" class="col-md-6 col-sm-6 text-center">
        <div style="vertical-align: middle;">
            <h1 style="color: black;margin-top:8%;">
                <span style="font-weight: 1000;font-family: Caveat">Raw Video Acquisition</span> 
            </h1>
            <h4 style="color: black;text-align: left;margin-top:4%;font-family:Calibri;">
                We collect stereo videos from four data sources: 
                <span style="font-weight: 800;">movies, animations, documentaries, and web videos. </span>
                A total of 60 movies, animations, and documentaries in Blu-ray format are collected. 
                We also crawl 739 web stereo videos from YouTube with the keywords such as “stereoscopic” and “stereo”. 
                To balance the realism and diversity, only 24 movies, animations, and documentaries are retained. 
            </h4>
        </div>
    </div>
    <div style="height: 16%;margin-top: 2%;" class="col-md-6 col-sm-6 text-center">
        <img style="max-width: 100%;max-height: 100%;border-radius:2%" src="construct_page-0002.png" >
    </div>

    <div style="height: 16%;margin-top: 0%;" class="col-md-12 col-sm-12 text-center">
        <h1 style="color: black;margin-top:2%;">
            <span style="font-weight: 1000;font-family: Caveat">Data Pre-processing</span> 
        </h1>
        <h4 style="color: black;text-align: center;margin-top:1%;font-family:Calibri;max-width: 60%;">
            Having obtained the raw videos, we use <span style="font-weight: 800;color: red;"><a href="https://ffmpeg.org/">FFmpeg</a></span> and 
            <span style="font-weight: 800;color: red;"><a href="https://www.scenedetect.com/">PySceneDetect</a></span> to split all the videos into 104,582 sequences. 
            We manually check and remove the duplicated, chaotic, and blur scenes. 
            Videos that are wrongly split by the scene detect tools are also removed. 
            Finally, we reserve 32,405 videos with more than six million frames for disparity annotations.
        </h4>
    </div>


</section>
