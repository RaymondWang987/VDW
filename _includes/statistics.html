<section class="bg-primary container statistics-pagepadding" style="background-color:lightgray;width:100%;opacity: 1;" id="statistics">
    <!-- <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h2 class="section-heading">We've got what you need!</h2>
                <hr class="light">#E6E7E8
                <p class="text-faded">Start Bootstrap has everything you need to get your new website up and running in no time! All of the templates and themes on Start Bootstrap are open source, free to download, and easy to use. No strings attached!</p>
                <a href="#" class="btn btn-default btn-xl">Get Started!</a>
            </div>
        </div>
    </div> -->
    <div class="container" style="padding:0% 2% 8% 2%;background-color:white;width:100%;opacity: 1;">

        <!-- <div style="width: 100%;" class="container construct-container construct-margin">
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <img style="max-width: 80%;max-height: 100%;border-radius:2%;" src="statistics_page-0001.png" >
            </div>
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <div style="vertical-align: middle;">
                    <h6 style="color: black;">
                        <span style="font-weight: 1000;font-family: Caveat">Dataset Comparisons</span> 
                    </h6>
                    <h4 style="color: black;margin:2% auto;font-family:Calibri;hyphens: auto;max-width: 100%;text-align: justify;" class="text-justify">
                        VDW dataset has larger numbers of video scenes. 
                        Compared with the closed-domain datasets, VDW is not restricted to a certain scene, which is more helpful to train a robust video depth model. 
                        For the natural-scene datasets, VDW has more than ten times the number of videos as the previous largest dataset <span style="font-weight: 800;color: #007AFC;"><a href="https://sites.google.com/view/wsvd/home" style="color: #007AFC;">WSVD</a></span>. 
                        It is also worth noticing that our VDW dataset has higher resolutions. We only collect videos over 1080p and crop them to 1880 × 800 to remove black bars and subtitles. 
                    </h4>
                </div>
            </div>
        </div>
        
        <div style="width: 100%;" class="container construct-container construct-margin">
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <div style="vertical-align: middle;">
                    <h6 style="color: black;">
                        <span style="font-weight: 1000;font-family: Caveat">Objective Statistics</span> 
                    </h6>
                    <h4 style="color: black;margin:2% auto;font-family:Calibri;hyphens: auto;max-width: 90%;text-align: justify;" class="text-justify">
                        VDW contains 14,203 videos with 2,237,320 frames. The total data collection and processing time takes over six months and about 4,000 man-hours. To verify the diversity of scenes and entities in our dataset, we conduct semantic segmentation by 
                        <span style="font-weight: 800;color: #007AFC;"><a href="https://github.com/facebookresearch/Mask2Former" style="color: #007AFC;">Mask2Former</a></span> trained on <span style="font-weight: 800;color: #007AFC;"><a href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" style="color: #007AFC;">ADE20k</a></span>. 
                        All the 150 categories are covered in our dataset, and each category can be found in at least 50 videos. The five categories that present most frequently are person (97.2%), wall (89.1%), floor (63.5%), ceiling (46.5%), and tree (42.3%). 
                    </h4>
                </div>
            </div>
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <img style="max-width: 80%;max-height: 100%;border-radius:2%" src="statistics_page-0002.png" >
            </div>
        </div>

        <div style="width: 100%;" class="container construct-container">
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <img style="max-width: 60%;max-height: 60%;border-radius:2%;" src="statistics_page-0003.png" >
                <h6 style="color: black;margin-top:1%;">
                    <span style="font-weight: 1000;font-family: Caveat">VDW Training Set</span> 
                </h6>
            </div>
            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                <div style="vertical-align: middle;">
                    <h6 style="color: black;">
                        <span style="font-weight: 1000;font-family: Caveat">Train&nbsp;/&nbsp;Test Split</span> 
                    </h6>
                    <h4 style="color: black;margin:2% auto 4% auto;font-family:Calibri;hyphens: auto;max-width: 90%;text-align: justify;" class="text-justify">
                        We randomly adopts 104 videos with 13,963 frames as the test set. The testing videos adopt different data sources from the training data, i.e., different movies, web videos, or animations. Our VDW not only alleviates the data shortage for learning-based approaches, but also serves as a comprehensive benchmark for video depth.
                    </h4>
                    <img style="max-width: 80%;max-height: 100%;border-radius:2%;" src="statistics_page-0004.png" >
                    <h6 style="color: black;margin-top:1%;">
                        <span style="font-weight: 1000;font-family: Caveat">VDW Testing Set</span> 
                    </h6>
                </div>
            </div>
        </div> -->




        <!-- ----------------- -->
        <div style="text-align: center;color: rgb(50, 50, 50);max-width: 96%;margin: 1% auto 2% auto;">
            <p style="font-family: Roboto;font-size: 3vw;font-weight: bolder;margin: 0% 1% auto;text-align: left;" class="sec-title">Statistics</p>
        </div>

        <div class="tab_contents" style="max-width: 90%;margin: auto;">
            <ul class="tab_nav">
                <li class="tabNav_active">
                    <span style="font-size: 1.2vw;font-family: 'Franklin Gothic Medium';">Dataset Comparisons</span>
                </li>
                <li>
                    <span style="font-size: 1.2vw;font-family: 'Franklin Gothic Medium';">Objective Statistics</span>
                </li>
                <li>
                    <span style="font-size: 1.2vw;font-family: 'Franklin Gothic Medium';">Train / Test Split</span>
                </li>
            </ul>
            <ul class="tab_box" style="color: black;max-width: 90%;padding: 2% 2% auto;margin: auto;">
                <li class="tabBox_active">
                    <div>
                        <span class="statistics-tabletext">
                            VDW dataset has larger numbers of video scenes. Compared with the closed-domain datasets, VDW is not restricted to a certain scene, which is more helpful to train a robust video depth model. For the natural-scene datasets, VDW has more than ten times the number of videos as the previous largest dataset 
                            <span style="font-weight: 800;color: #007AFC;"><a href="https://sites.google.com/view/wsvd/home" style="color: #007AFC;">WSVD</a></span>. 
                            It is also worth noticing that our VDW dataset has higher resolutions. We only collect videos over 1080p and crop them to 1880 × 800 to remove black bars and subtitles. 
                        </span>
                        <div style="text-align: center;margin-top: 2%;"><img style="max-width: 80%;margin: auto;" src="statistics_page-0001.png" alt="Comparisons"></div>
                    </div>
                </li>
                <li>
                    <div>
                        <span class="statistics-tabletext">
                            VDW contains 14,203 videos with 2,237,320 frames. The total data collection and processing time takes over six months and about 4,000 man-hours. To verify the diversity of scenes and entities in our dataset, we conduct semantic segmentation by 
                            <span style="font-weight: 800;color: #007AFC;"><a href="https://github.com/facebookresearch/Mask2Former" style="color: #007AFC;">Mask2Former</a></span> trained on <span style="font-weight: 800;color: #007AFC;"><a href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" style="color: #007AFC;">ADE20k</a></span>. 
                            All the 150 categories are covered in our dataset, and each category can be found in at least 50 videos. The five categories that present most frequently are person (97.2%), wall (89.1%), floor (63.5%), ceiling (46.5%), and tree (42.3%). 
                        </span>
                        <div style="text-align: center;margin-top: 2%;"><img style="max-width: 80%;margin: auto;" src="statistics_page-0002.png" alt="Statistics"></div>
                    </div>
                </li>
                <li>
                    <div>
                        <span class="statistics-tabletext">
                            We randomly adopts 104 videos with 13,963 frames as the test set. The testing videos adopt different data sources from the training data, i.e., different movies, web videos, or animations. Our VDW not only alleviates the data shortage for learning-based approaches, but also serves as a comprehensive benchmark for video depth.
                        </span>

                        <div style="width: 100%;margin: 2% auto;text-align: center;" class="container construct-container">
                            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                                <img style="max-width: 100%;max-height: 100%;border-radius:2%;" src="statistics_page-0003.png" >
                                <p style="color: gray;font-size: 1.2vw;font-family:Calibri;text-align: center;">
                                    VDW Training Set
                                </p>
                            </div>
                            <div style="margin: auto;" class="construct-item height-md-12 height-sm-12 height-xs-6 col-md-6 col-sm-6 col-xs-12 text-center">
                                <img style="max-width: 100%;max-height: 100%;border-radius:2%;" src="statistics_page-0004.png" >
                                <p style="color: gray;font-size: 1.2vw;font-family:Calibri;text-align: center;">
                                    VDW Testing Set
                                </p>
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </div>
    
    </div>
        

</section>


